{
  "Models Data": [
    {
      "Model Name": null,
      "Model Type": "RNN",

      "Model Args": {
        "embedding_dim": 32,
        "num_rnn_layers": 2,
        "rnn_hidden_dim": 64,
        "num_mlp_layers": 2,
        "mlp_hidden_size": 64
      },

      "Training Args": {
        "Num Epochs": 50,
        "Batch Size": 1024,
        "Learning Rate": 1e-4,
        "Weight Decay": 0
      }
    },

    {
      "Model Name": null,
      "Model Type": "LSTM",

      "Model Args": {
        "embedding_dim": 32,
        "num_lstm_layers": 2,
        "lstm_hidden_size": 64,
        "num_mlp_layers": 2,
        "mlp_hidden_size": 64
      },

      "Training Args": {
        "Num Epochs": 50,
        "Batch Size": 1024,
        "Learning Rate": 1e-4,
        "Weight Decay": 0
      }
    },

    {
      "Model Name": "SSM",
      "Model Type": "Mamba",

      "Model Args": {
        "embedding_dim": 16,
        "d_model": 16,
        "num_layers": 3,
        "d_state": 8,
        "expand_factor": 2,
        "d_conv": 4
      },

      "Training Args": {
        "Num Epochs": 25,
        "Batch Size": 1024,
        "Learning Rate": 1e-4,
        "Weight Decay": 0
      }
    },

    {
      "Model Name": null,
      "Model Type": "TransformerEncoder",

      "Model Args": {
        "max_sequence_length": 501,
        "embedding_dim": 64,
        "num_encoder_layers": 8,
        "num_encoder_heads": 8,
        "dim_encoder_feedforward": 512,
        "num_ffnn_layers": 1,
        "ffnn_hidden_dim": 32
      },

      "Training Args": {
        "Num Epochs": 20,
        "Batch Size": 1024,
        "Learning Rate": 1e-5,
        "Weight Decay": 0
      }
    }
  ],

  "Training Dataset": "Zero Centre len 75",
  "Test Datasets": [
    "Zero Centre len 150",
    "Zero Centre len 250",
    "Zero Centre len 500"
  ],

  "Test Batch Size": 32,

  "Experiment Name": "Zero Centre Language"
}